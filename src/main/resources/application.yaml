server:
  port: 8082

spring:
  application:
    name: pms-trade-capture

  # Database & JPA
  datasource:
    url: jdbc:postgresql://${DB_HOST:localhost}:${DB_PORT:5432}/${DB_NAME:pmsdb}
    username: ${DB_USERNAME:pms}
    password: ${DB_PASSWORD:pms}
    hikari:
      maximum-pool-size: ${TRADE_CAPTURE_POOL_SIZE:20}
      keepalive-time: 30000

  jpa:
    open-in-view: ${JPA_OPEN_IN_VIEW:false}
    properties:
      hibernate:
        ddl-auto: ${DB_DDL_AUTO:update}
        jdbc:
          batch_size: ${TRADE_CAPTURE_BATCH_SIZE:500} # Increased to 500 for better batching
        order_inserts: ${ORDER_INSERTS:true}
        order_updates: ${ORDER_UPDATES:true}

  liquibase:
    change-log: classpath:db/changelog/db.changelog-master.yaml
    clear-checksums: true

  # Kafka (Producer)
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: io.confluent.kafka.serializers.protobuf.KafkaProtobufSerializer
      acks: all
    properties:
      schema.registry.url: ${SCHEMA_REGISTRY_URL:http://localhost:8081}
  dokcer:
    compose:
      enabled: false

rttm:
  client:
    mode: ${RTTM_MODE:kafka}
    kafka:
      bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
      topics:
        trade-events: ${KAFKA_TOPIC_TRADE_EVENTS:rttm.trade.events}
        dlq-events: ${KAFKA_TOPIC_DLQ_EVENTS:rttm.dlq.events}
        queue-metrics: ${KAFKA_TOPIC_QUEUE_METRICS:rttm.queue.metrics}
        error-events: ${KAFKA_TOPIC_ERROR_EVENTS:rttm.error.events}
    send-timeout-ms: ${RTTM_SEND_TIMEOUT_MS:3000}
    retry:
      max-attempts: ${RTTM_RETRY_MAX_ATTEMPTS:3}
      backoff-ms: ${RTTM_RETRY_BACKOFF_MS:100}

logging:
  level:
    root: INFO
    # Enable detailed logs for your application code
    com.pms.pms_trade_capture: DEBUG
    # Show SQL queries (optional, good for debugging batch inserts)
    org.hibernate.SQL: INFO
    # Show basic Kafka/RabbitMQ activity without flooding
    org.springframework.kafka: INFO
    org.springframework.amqp: INFO

# App Specific Configs
app:
  rabbit:
    stream:
      name: ${RABBITMQ_STREAM_NAME:trade-stream}
      host: ${RABBITMQ_HOST:localhost}
      port: ${RABBITMQ_STREAM_PORT:5552}
      # Fixed likely copy-paste error in variable name (was RABBIT_STREAM_PORT)
      consumer-name: ${TRADE_CAPTURE_CONSUMER_GROUP:trade-capture-group}
      username: ${RABBITMQ_USERNAME:guest}
      password: ${RABBITMQ_PASSWORD:guest}

  ingest:
    batch:
      # Max size of the in-memory buffer before forced flush
      max-size: ${INGEST_BATCH_MAX_SIZE:500}
      # Max time to wait before flushing buffer
      flush-interval-ms: ${INGEST_BATCH_FLUSH_INTERVAL:100}

  outbox:
    trade-topic: ${INCOMING_TRADES_TOPIC:raw-trades-topic}
    max-retries: ${OUTBOX_MAX_RETRIES:3}
    # Dynamic Batching Settings (AdaptiveBatchSizer)
    target-latency-ms: ${OUTBOX_TARGET_LATENCY:200}
    min-batch: ${OUTBOX_MIN_BATCH:10}
    max-batch: ${OUTBOX_MAX_BATCH:2000}
    # Polling interval (set to -1 if using continuous loop, or positive for fixed delay)
    poll-interval-ms: ${OUTBOX_POLL_INTERVAL:100}
    # Initial batch size
    batch-size: ${OUTBOX_BATCH_SIZE:200}
    concurrency: ${OUTBOX_CONCURRENCY:4}

resilience4j:
  circuitbreaker:
    instances:
      pmsDb:
        registerHealthIndicator: true
        slidingWindowSize: 10 # Check last 10 calls
        failureRateThreshold: 50 # If 5/10 fail, OPEN the circuit
        waitDurationInOpenState: 10s # Wait 10s before trying again (Half-Open)
        permittedNumberOfCallsInHalfOpenState: 3
        automaticTransitionFromOpenToHalfOpenEnabled: true
        # TRICK: Don't trip the breaker for bad data (Duplicate Key, etc.)
        ignoreExceptions:
          - org.springframework.dao.DataIntegrityViolationException
          - java.lang.IllegalArgumentException
