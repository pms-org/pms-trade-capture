version: "3.8"

services:
  # 1. RabbitMQ with Stream Plugin Enabled
  rabbitmq:
    image: rabbitmq:3.13-management
    container_name: rabbitmq
    environment:
      RABBITMQ_DEFAULT_USER: guest
      RABBITMQ_DEFAULT_PASS: guest
    ports:
      - "5672:5672"
      - "15672:15672"
      - "5552:5552"
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
      - ./rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf:ro
    command: >
      bash -c "
        rabbitmq-plugins enable rabbitmq_stream &&
        rabbitmq-server
      "
    healthcheck:
      test: ["CMD-SHELL", "rabbitmq-diagnostics -q ping"]
      interval: 10s

      timeout: 5s
      retries: 5
      start_period: 30s

  # 2. PostgreSQL Database
  postgres:
    image: postgres:16
    container_name: postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: pms
      POSTGRES_PASSWORD: pms
      POSTGRES_DB: pmsdb
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U pms -d pmsdb"]
      interval: 5s
      timeout: 5s
      retries: 5

  # 3. Kafka Broker
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    hostname: kafka
    container_name: kafka
    environment:
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CLUSTER_ID: "dOFfvAcdQZKE60Enfcsefg"
      CLUSTER_ID: "dOFfvAcdQZKE60Enfcsefg"
      KAFKA_NODE_ID: 1
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:19092,CONTROLLER://0.0.0.0:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:19092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      # Single-node setup: set default replication factors to 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
    ports:
      - "9092:9092"
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "kafka-broker-api-versions --bootstrap-server localhost:9092",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # 4. Schema Registry (Required for Protobuf)
  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.0
    container_name: schema-registry
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:19092
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    ports:
      - "8081:8081"
    depends_on:
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8081/subjects || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # 5. Trade Capture Application
  trade-capture:
    build: .
    container_name: trade-capture-app
    ports:
      - "8082:8082"
    volumes:
      - ./logs:/app/logs
    environment:
      SPRING_PROFILES_ACTIVE: docker
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/pmsdb
      SPRING_DATASOURCE_USERNAME: pms
      SPRING_DATASOURCE_PASSWORD: pms
      SPRING_RABBITMQ_HOST: rabbitmq
      SPRING_RABBITMQ_PORT: 5672
      DB_HOST: postgres
      DB_NAME: pmsdb
      DATASOURCE_USER: pms
      DATASOURCE_PASS: pms
      DATASOURCE_HIKARI_POOL_SIZE: 20
      JPA_OPEN_IN_VIEW: false
      JDBC_BATCH_SIZE: 500
      SPRING_RABBITMQ_USERNAME: guest
      SPRING_RABBITMQ_PASSWORD: guest
      APP_RABBIT_STREAM_HOST: rabbitmq
      APP_RABBIT_STREAM_PORT: 5552
      APP_RABBIT_STREAM_NAME: trade-stream
      APP_RABBIT_STREAM_CONSUMER_NAME: trade-capture-group
      APP_RABBIT_STREAM_USERNAME: guest
      APP_RABBIT_STREAM_PASSWORD: guest
      SPRING_KAFKA_BOOTSTRAP_SERVERS: kafka:19092
      KAFKA_BOOTSTRAP_SERVERS: kafka:19092
      SCHEMA_REGISTRY_URL: http://schema-registry:8081
      SPRING_KAFKA_PRODUCER_KEY_SERIALIZER: org.apache.kafka.common.serialization.StringSerializer
      SPRING_KAFKA_PRODUCER_VALUE_SERIALIZER: io.confluent.kafka.serializers.protobuf.KafkaProtobufSerializer
      SPRING_KAFKA_PRODUCER_PROPERTIES_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      SPRING_KAFKA_PRODUCER_PROPERTIES_AUTO_REGISTER_SCHEMAS: true
      BATCH_SIZE: 500
      BATCH_TIMEOUT_MS: 100
    depends_on:
      postgres:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    healthcheck:
      test:
        ["CMD-SHELL", "curl -f http://localhost:8082/actuator/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # 6. PMS Simulation
  simulation:
    build: ../pms-simulation
    container_name: pms-simulation
    depends_on:
      rabbitmq:
        condition: service_healthy
      postgres:
        condition: service_healthy
    environment:
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_STREAM_PORT: 5552
      RABBITMQ_STREAM_NAME: trade-stream
      # Use PostgreSQL database
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/pmsdb
      SPRING_DATASOURCE_USERNAME: pms
      SPRING_DATASOURCE_PASSWORD: pms
      SPRING_DATASOURCE_DRIVER_CLASS_NAME: org.postgresql.Driver
      SPRING_JPA_HIBERNATE_DDL_AUTO: update
      SPRING_JPA_DATABASE_PLATFORM: org.hibernate.dialect.PostgreSQLDialect
    ports:
      - "4000:4000"
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:4000/actuator/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
  redis:
    image: "redislabs/redismod"
    hostname: redis
    container_name: redis-server
    ports:
      - "6379:6379"
    volumes:
      - ./data:/data
    entrypoint: >
      redis-server
        --loadmodule /usr/lib/redis/modules/redisai.so
          ONNX redisai_onnxruntime/redisai_onnxruntime.so
          TF redisai_tensorflow/redisai_tensorflow.so
          TFLITE redisai_tflite/redisai_tflite.so
          TORCH redisai_torch/redisai_torch.so   
        --loadmodule /usr/lib/redis/modules/redisearch.so
        --loadmodule /usr/lib/redis/modules/redisgraph.so
        --loadmodule /usr/lib/redis/modules/redistimeseries.so
        --loadmodule /usr/lib/redis/modules/rejson.so
        --loadmodule /usr/lib/redis/modules/redisbloom.so
        --loadmodule /usr/lib/redis/modules/redisgears.so
        --appendonly yes
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
  control-center:
    image: confluentinc/cp-enterprise-control-center:7.6.0
    hostname: control-center
    container_name: control-center
    depends_on:
      - kafka
      - schema-registry
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: "PLAINTEXT://kafka:29092"
      CONTROL_CENTER_SCHEMA_REGISTRY_URLS: "http://schema-registry:8081"
      CONTROL_CENTER_CONNECT_CLUSTER: ""
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      PORT: 9021

  # validation-service:
  #   build:
  #     context: ../pms-validation
  #     dockerfile: docker/Dockerfile
  #   container_name: validation-service
  #   environment:
  #     SPRING_APPLICATION_NAME: validation
  #     DB_HOST: postgres
  #     DB_PORT: "5432"
  #     DB_NAME: pmsdb
  #     DATASOURCE_USER: pms
  #     DB_PASS: pms
  #     DATASOURCE_DRIVER: org.postgresql.Driver
  #     HIBERNATE_DDL_AUTO: update
  #     HIBERNATE_SHOW_SQL: "false"
  #     HIBERNATE_FORMAT_SQL: "true"
  #     HIBERNATE_DIALECT: org.hibernate.dialect.PostgreSQLDialect
  #     REDIS_HOST: redis
  #     REDIS_PORT: "6379"
  #     REDIS_TIMEOUT: 2s
  #     CACHE_TYPE: redis
  #     KAFKA_BOOTSTRAP_SERVERS: kafka:19092
  #     KAFKA_CONSUMER_GROUP_ID: validation-consumer-group
  #     SCHEMA_REGISTRY_URL: http://schema-registry:8081
  #     SERVER_PORT: "8080"
  #     INCOMING_TRADES_TOPIC: raw-trades-topic
  #     OUTGOING_VALID_TRADES_TOPIC: valid-trades-topic
  #     OUTGOING_INVALID_TRADES_TOPIC: invalid-trades-topic
  #     LOGGING_LEVEL: DEBUG
  #   ports:
  #     - "8080:8080"
  #   depends_on:
  #     - postgres
  #     - kafka
  #     - schema-registry
  #     - redis

volumes:
  pgdata:
  rabbitmq_data:
  kafka_data:
